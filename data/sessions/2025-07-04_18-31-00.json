[
  [
    "what is overfitting",
    "Overfitting occurs when a model learns the training data *too* well, to the point that it captures noise, outliers, and specific nuances of the training set rather than the underlying generalizable patterns.  Think of it like memorizing the answers to a practice exam instead of understanding the underlying concepts.  The model becomes highly complex, effectively \"memorizing\" the training data, which leads to excellent performance on the training set itself but poor performance on unseen data (test data).  As the context explains, a highly overfit model like the 53-degree polynomial attempting to fit startup growth data captures every wiggle in the training data, making it useless for predicting future growth.  Conversely, a simple straight line (degree 1 polynomial) might underfit the data, failing to capture important trends.\n\nThe context also connects overfitting to penalized regression.  In penalized regression, we introduce a penalty term that discourages overly complex models. This penalty, in effect, forces the model to prioritize simpler explanations, accepting a slightly worse fit on the training data in exchange for improved generalization to unseen data. This is analogous to requiring \"more data to convince us that there is a strong relationship\" between the input and output variables.  By accepting a bit of bias (worse training fit), we reduce variance (sensitivity to noise) and improve the model's ability to generalize."
  ]
]